{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030c4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fewshot_cxray.config import Config\n",
    "\n",
    "from fewshot_cxray.utils import *\n",
    "from fewshot_cxray.loss import *\n",
    "from fewshot_cxray.model import *\n",
    "from fewshot_cxray.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174a9ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id='cuda:0'\n",
    "\n",
    "resize = 2048\n",
    "device = torch.device(device_id if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed54fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "\n",
    "cfg.batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828ef8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193730\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(cfg=cfg, out_dir='C:\\\\Users\\\\saura\\\\Notebooks\\\\output')\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "val_dataset = build_dataset(mode='val', cfg=cfg, out_dir='C:\\\\Users\\\\saura\\\\Notebooks\\\\output')\n",
    "\n",
    "len(val_dataset)\n",
    "\n",
    "test_dataset = build_dataset(mode='test', cfg=cfg,out_dir='C:\\\\Users\\\\saura\\\\Notebooks\\\\output')\n",
    "\n",
    "image_datasets = {\n",
    "    'train': dataset, 'val': val_dataset, 'test': test_dataset\n",
    "}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=cfg.batch_size,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "              for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7782a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('G:\\\\smahindr\\\\mimic_novel_labels.pkl'), 'rb') as f:\n",
    "    dt = pickle.load(f)\n",
    "\n",
    "novel_datasets = pd.DataFrame.from_dict(dt['label'], orient='index')\n",
    "\n",
    "novel_datasets = novel_datasets[novel_datasets.index.isin(list(dt['image'].keys()))]\n",
    "\n",
    "n_way = 5\n",
    "n_shots = 200\n",
    "\n",
    "import random\n",
    "sampled_classes = random.sample([14,15,16,17,18], 5)\n",
    "\n",
    "num_episodes = 100\n",
    "\n",
    "novel_datasets = novel_datasets[~novel_datasets.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6b24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_norm = torch.load('train_mean_normal_baseline.pt',\n",
    "                              map_location=device)\n",
    "train_mean_norm = train_mean_norm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c68684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_mean_norm4 = torch.load('train_mean_tukey.pt', map_location=device)\n",
    "train_mean_norm4 = train_mean_norm4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31ebe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b16826",
   "metadata": {},
   "outputs": [],
   "source": [
    "pthl2 = 'D:\\\\MIMIC_CXR\\\\models\\\\residual_network_clip_2048_12.pth'\n",
    "\n",
    "model_finetune = ImageResNet(block=BasicBlock, \n",
    "             layers=[2, 2, 2, 2, 2, 2, 2],\n",
    "                output_channels = 14, zero_init_residual=False, groups=1, \n",
    "             width_per_group=64, replace_stride_with_dilation=None, norm_layer=None)\n",
    "\n",
    "model_finetune, _, _ = load_checkpoint(model_finetune, optim.SGD(model_finetune.parameters(), lr=0.0001, momentum=0.9), \n",
    "                                      pthl2\n",
    "                                      ) \n",
    "num_ftrs = model_finetune.fc1.in_features\n",
    "model_finetune.fc1 = nn.Linear(num_ftrs, 5)\n",
    "model_finetune.fc1.weight.requires_grad = True\n",
    "model_finetune.fc1.bias.requires_grad = True\n",
    "\n",
    "# models.append(model_finetune2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e12345",
   "metadata": {},
   "outputs": [],
   "source": [
    "pthrcna = 'model_nca_june_13_added_unmatched_neg.pth'\n",
    "model_rcna = ImageResNet(block=BasicBlock, \n",
    "             layers=[2, 2, 2, 2, 2, 2, 2],\n",
    "                output_channels = 14, zero_init_residual=False, groups=1, \n",
    "             width_per_group=64, replace_stride_with_dilation=None, norm_layer=None)\n",
    "\n",
    "model_rcna, _, _ = load_checkpoint(model_rcna, optim.SGD(model_rcna.parameters(), lr=0.0001, momentum=0.9), \n",
    "                                      pthrcna\n",
    "                                      ) \n",
    "model_rcna = model_rcna.to(device)\n",
    "model_rcna.eval()\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f23e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_pickle(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def distribution_calibration(query, base_means, base_cov, k,alpha=0.21):\n",
    "    dist = []\n",
    "    for i in range(len(base_means)):\n",
    "        dist.append(np.linalg.norm(query-base_means[i]))\n",
    "    index = np.argpartition(dist, k)[:k]\n",
    "    mean = np.concatenate([np.array(base_means)[index], query[np.newaxis, :]])\n",
    "    calibrated_mean = np.mean(mean, axis=0)\n",
    "    calibrated_cov = np.mean(np.array(base_cov)[index], axis=0)+alpha\n",
    "\n",
    "    return calibrated_mean, calibrated_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e4c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1febbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_means = []\n",
    "base_cov = []\n",
    "datatype = 'base'\n",
    "base_features_path = '%s_features_12_4.plk'%datatype\n",
    "with open(base_features_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    for key in data.keys():\n",
    "        feature = np.array(data[key])\n",
    "        mean = np.mean(feature, axis=0)\n",
    "        cov = np.cov(feature.T)\n",
    "        base_means.append(mean)\n",
    "        base_cov.append(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9448c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetune = model_finetune.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f9e991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d70a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beta=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da12e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75607071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotNCALossMultiLabel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes=14,\n",
    "        temperature=1,\n",
    "        batch_size=16,\n",
    "        num_labels=14,\n",
    "        frac_negative_samples=1,\n",
    "        frac_positive_samples=1,\n",
    "    ):\n",
    "        super(FewShotNCALossMultiLabel, self).__init__()\n",
    "        self.temperature = torch.tensor(float(temperature), requires_grad=True).to(device)\n",
    "        self.num_labels=num_labels\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        n, d = pred.shape\n",
    "\n",
    "        p_norm = torch.pow(torch.cdist(pred, pred), 2)\n",
    "        p_norm[p_norm < 1e-10] = 1e-10\n",
    "        dist = torch.exp(-1 * p_norm / self.temperature).to(device)        \n",
    "\n",
    "        all_pos = torch.zeros(n,n).to(device)\n",
    "        all_negs = torch.zeros(n,n).to(device)\n",
    "        negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
    "\n",
    "        for i in range(self.num_labels):\n",
    "            positives = (target[:, i, None]*target[:, i, None].T)\n",
    "#             weighted_positives = positives*pos_weights[i]\n",
    "#             negatives = (negated_target[:, i, None]*negated_target[:, i, None].T)\n",
    "#             unmatched = (target[:, i, None]*negated_target[:, i, None].T)#*pos_weights[i]\n",
    "#             unmatched_neg = (negated_target[:, i, None]*target[:, i, None].T)\n",
    "            all_pos+= positives #weighted_positives\n",
    "#             all_negs += negatives\n",
    "#             all_negs += unmatched\n",
    "#             all_negs += unmatched_neg\n",
    "#             all_negs += positives\n",
    "\n",
    "        negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
    "#         negatives_matrix = torch.tensor(all_negs, dtype=torch.int16).to(device)\n",
    "\n",
    "        positives_matrix = (\n",
    "                    torch.tensor(all_pos, dtype=torch.int16)\n",
    "                ).to(device)\n",
    "\n",
    "        positives_matrix.fill_diagonal_(0)\n",
    "#         print(positives_matrix[0, :])\n",
    "#         print(negatives_matrix[0, :])\n",
    "#         print(dist[0, :])\n",
    "        numerators = torch.sum(dist * positives_matrix, axis=0)\n",
    "        denominators = torch.sum(dist* negatives_matrix, axis=0)\n",
    "\n",
    "        denominators[denominators < 1e-10] = 1e-10\n",
    "        frac = numerators / (numerators + denominators )\n",
    "\n",
    "        loss = -1 * torch.sum(torch.log(frac[frac >= 1e-10])) / (n)   \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa9e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "novelNCA = FewShotNCALossMultiLabel(num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07619fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgRegv(torch.nn.Module):\n",
    "    '''\n",
    "    TODO: pre-training\n",
    "    from power to voronoi\n",
    "    '''\n",
    "    def __init__(self, dim, nla):\n",
    "        super(LgRegv, self).__init__()\n",
    "        self.linear = nn.Linear(dim, nla, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ba = - torch.sum((self.linear.weight/2)**2, dim=1)\n",
    "        ba = ba.float()\n",
    "#         ba = Variable(ba.float(), requires_grad=False)\n",
    "        y_hat = self.linear(x) + ba\n",
    "        y_hat = torch.sigmoid(y_hat)\n",
    "        return y_hat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c56d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e24cd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR(X, Y, learning_rate = 0.01, ep = 100, l2 = False):\n",
    "    \n",
    "    model = LgRegv(2048, 5)\n",
    "    model = model.to(device) \n",
    "    X= torch.from_numpy(X).to(device).float()\n",
    "    Y = torch.from_numpy(Y).to(device).float()\n",
    "    \n",
    "    if l2:\n",
    "        X = X / torch.norm(X.float(), p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "    print('training LR')\n",
    "    for i in range(1, ep + 1):\n",
    "        Z = model(X)\n",
    "        loss = loss_function(Z, Y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.clip_max_norm)  \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return model.linear.weight.data.detach().cpu().numpy(), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c364f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fewshot(all_preds, y_trues):\n",
    "    class_auc = []\n",
    "\n",
    "    for i in range(all_preds.shape[-1]): \n",
    "        if len(np.unique(y_trues[:, i])) <= 1:\n",
    "            continue\n",
    "        class_auc.append(roc_auc_score(y_trues[:,i],all_preds[:,i]))\n",
    "    return class_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9175c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 10\n",
    "num_episodes = 50\n",
    "beta=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a70848d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 455.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [24:40<20:09:22, 1480.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7120176167395622 0.7111989484517252 0.6975156058619831 0.7015542391749868 0.6271367053214707 0.6292155805582567\n",
      "0.708461416835439 0.7271065926505044 0.7273552649185524 0.7198112091404802\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1654.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [48:50<19:29:56, 1462.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7097133658631312 0.6971511704782577 0.7038121741703037 0.6959161546833228 0.6133147519929288 0.660073445214493\n",
      "0.7119146685943392 0.7243086406748196 0.7248053029396772 0.7240797625132465\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1255.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [1:13:13<19:05:52, 1462.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714977523025241 0.7022679536388606 0.7002198927185566 0.7009089301403418 0.605270785521887 0.6684321677714312\n",
      "0.7125603597604516 0.7278532940459096 0.7289786490716429 0.7309773412237667\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 192.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [1:40:33<19:35:00, 1532.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7028705585883723 0.7030170432453433 0.6941936865078783 0.6868755968002982 0.6038722134792182 0.66535783741813\n",
      "0.7036547760141989 0.7251703269470379 0.7259712355894464 0.7271760403830084\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 250.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [2:12:19<20:50:24, 1667.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6978860551860461 0.7016785659292664 0.6912088904390233 0.6825543545568931 0.6026932568035275 0.6624025888104017\n",
      "0.6995736007422815 0.722727424471566 0.7233709831544262 0.7241516994672469\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 867.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [2:41:24<20:41:59, 1693.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6997738784246467 0.7056876823717951 0.693077989089271 0.6846819216732397 0.6000848729815643 0.6709681627696531\n",
      "0.7015538935040156 0.7253602645575187 0.7259820670266559 0.7278683993475857\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 357.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6998873697791418 0.7026311133334447 0.6929591772961406 0.6839756102674509 0.5985527138454311 0.6740529885313291\n",
      "0.7012717581916107 0.7235783679862096 0.7241609924493003 0.7270208329865688\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [3:05:38<19:17:45, 1615.47s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1672.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [3:29:26<18:09:07, 1555.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6960001109780862 0.6978450447350684 0.6894925440337301 0.6777819863978685 0.5950750862263653 0.6709281509591769\n",
      "0.6973317145207278 0.7179664145762464 0.7184222201761631 0.7214890215591542\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 358.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [3:53:54<17:24:25, 1528.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6947870629690741 0.6977326573937165 0.6880179791946691 0.676762955115223 0.5935091150130486 0.670458028167525\n",
      "0.6960114333688403 0.717396965393421 0.7178201185845862 0.7211763556208304\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 357.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [4:18:33<16:48:40, 1513.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692974416405231 0.6979061307762707 0.686315585102724 0.6749516061432572 0.5921074158116032 0.6732234464995506\n",
      "0.694349998050946 0.7164381479642732 0.716878451441873 0.7206419006970214\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6923916741121547 0.6973178560725709 0.6854781928379831 0.6743494181055882 0.5909902782973703 0.6731731840835173\n",
      "0.6936635206866949 0.7157773358301275 0.7162354646258398 0.7201634735522568\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [4:46:33<16:56:45, 1564.24s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1002.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6972512522611636 0.7007103254270418 0.6864763493121849 0.6794341974902149 0.5949158061239863 0.6773012112593455\n",
      "0.6955117798995764 0.7187504081388899 0.7192062268421414 0.7231924466290865\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [5:19:30<17:50:11, 1689.77s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 40.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6963332209550516 0.702381739302369 0.6876283066837683 0.6770414913326225 0.5948408182115649 0.6759697707076298\n",
      "0.6960371204198437 0.7204291233574533 0.7208071474415862 0.7246791379757861\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [5:50:46<17:56:43, 1746.04s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 98.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [6:21:11<17:41:59, 1770.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6992560642644631 0.7050444917640099 0.690243080686124 0.6792502872888146 0.5950706637414107 0.6798159126002515\n",
      "0.6985796646153724 0.7230537509559957 0.7234157426892421 0.7272374426133409\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1253.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [6:45:32<16:18:03, 1676.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6972363063175344 0.7020787659094234 0.6883337391087547 0.6771323649674774 0.5932976939529596 0.6792894121959445\n",
      "0.6964813830301589 0.7202593185785388 0.7206333944059733 0.7249461869204417\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1265.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [7:09:12<15:06:23, 1599.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6974888802985895 0.7004864504629332 0.6883071763321873 0.6767654755626411 0.5921928294700485 0.678329165745909\n",
      "0.6964829033853315 0.7190138248160609 0.7194790471373574 0.723891335029513\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1563.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [7:33:32<14:16:45, 1557.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6993203547460132 0.7019484347402855 0.6904361520119382 0.6782273992440417 0.5914340465484136 0.6806211595895355\n",
      "0.6985561292243505 0.7209223677847175 0.7213941421484877 0.7257582484961967\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1652.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [8:00:01<13:55:46, 1567.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7001067753763475 0.7023779354825276 0.6918242238624628 0.6789108869782372 0.5914417401056693 0.6822593444040641\n",
      "0.6997263917726847 0.7223387057502685 0.7228245067731744 0.7273306955039591\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:00<00:00, 46.10it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [8:24:28<13:14:01, 1536.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7007411806086932 0.7039724593547905 0.6928482183367064 0.6783844185456387 0.5911967459586246 0.6840130874991681\n",
      "0.7004908363456905 0.7236772191284224 0.7240954190708042 0.7285731340735158\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [8:48:56<12:38:08, 1516.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7010618398384804 0.7040434423217442 0.6934016052602782 0.6787402005224342 0.591250031828894 0.68408983084289\n",
      "0.7008915829459886 0.7239393373529974 0.7243598150703803 0.7286688669419591\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1651.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.7019293254207373 0.7048782023291035 0.6940230241667691 0.6787850633992835 0.5907942282533843 0.6838947700943293\n",
      "0.7017030411477236 0.7253401125529928 0.7257320238346643 0.7298427112325986\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [9:13:28<12:06:27, 1503.01s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1258.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6999718151392538 0.7031939975989722 0.6919299647818347 0.6773171745720314 0.5902687425056065 0.6809877218181629\n",
      "0.699665227432186 0.7232921388081199 0.7236919250084953 0.727715509093484\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [9:37:47<11:35:17, 1489.90s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1650.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [10:02:01<11:05:29, 1478.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7009310890901104 0.7047629933573364 0.6931248593381217 0.6780772372234868 0.5905764771485038 0.6808009132007169\n",
      "0.7007852883302261 0.7246042751247653 0.7249917341604047 0.7288068077166038\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1680.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.7008146712531637 0.705582710185707 0.693111644005404 0.678307241319962 0.5914126631231176 0.6821054739943131\n",
      "0.7006943229350578 0.7250215758939733 0.7253929156056026 0.7292465391292224\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [10:26:20<10:38:21, 1473.15s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1650.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.7015030656151109 0.7058338255610692 0.693538994307077 0.6784948300563708 0.5914047687632632 0.682991902616058\n",
      "0.7013428149775615 0.7252191964260473 0.7255768813189131 0.7295051896757683\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [10:50:36<10:11:36, 1467.85s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 78.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.7011722185600179 0.7052062164228653 0.6936630311645536 0.678191062661339 0.590773640010577 0.6836861841164763\n",
      "0.7012513809590627 0.7249112519979969 0.7252799734577055 0.729274143180969\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [11:16:30<9:57:33, 1493.88s/it] C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1650.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [11:40:52<9:28:54, 1484.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7004410519321354 0.7047654727889124 0.692293390828626 0.6781681841068815 0.5910040691581566 0.6839484471122579\n",
      "0.6999824816792035 0.7241323219043072 0.7245205119618139 0.7286418945652431\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 389.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [12:05:07<9:01:01, 1475.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003439947880211 0.7046349829731265 0.6922144596736788 0.6787385519999225 0.5909328101680656 0.6837621401426223\n",
      "0.6999804429218744 0.7238733587276126 0.7242617320723179 0.7282593449587331\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1589.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [12:29:17<8:33:46, 1467.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6986463157627568 0.7028617519887252 0.6914509162800276 0.6774641955432679 0.5903971799320039 0.6833632132412191\n",
      "0.6989484169672079 0.7221860141328295 0.7225856564850223 0.7266982937950456\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1252.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6988246354410346 0.7027159565132445 0.691577724440812 0.6775125152798015 0.5902079638109847 0.6828768080700781\n",
      "0.6989926842809567 0.7221315932797869 0.7225211035789691 0.7265775599112239\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [12:53:21<8:06:50, 1460.54s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1670.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6989894418457756 0.7029860271757331 0.6923917440383749 0.6778063007273655 0.5901434426546726 0.6837511741139614\n",
      "0.6996291575417082 0.7224786863587582 0.7228789532844041 0.7270475380955055\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [13:17:27<7:41:10, 1456.34s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1653.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6999874773101025 0.7044705232055539 0.6931130909492726 0.6780131107107127 0.5908908662332196 0.6845930151902861\n",
      "0.7004062320916166 0.7236600865072308 0.7240337200403022 0.7280176017515572\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [13:41:24<7:15:10, 1450.59s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1246.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.7003335103115127 0.7047454311840383 0.6936538072111171 0.679042170582455 0.5905865959971494 0.6855792864563557\n",
      "0.7009521180445891 0.7240416725355766 0.7244531727904472 0.7285101987970569\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [14:05:24<6:50:02, 1447.18s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1655.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.699322969255578 0.7036657440794678 0.6929886542421372 0.6792832921286482 0.5903265623847954 0.6852906425798119\n",
      "0.7002749310534591 0.7231044686726547 0.7235251602609308 0.7277727166464227\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [14:29:30<6:25:52, 1447.03s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1597.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6998244702280616 0.7040517122773963 0.6935692743346128 0.6797169608074076 0.5902173234037029 0.6850721186286101\n",
      "0.7008188088004348 0.7235844522169326 0.7240085244746022 0.7282552689012725\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [14:53:26<6:00:55, 1443.69s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1251.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [15:17:30<5:36:51, 1443.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7000650976015047 0.7045113821791665 0.6936593095525784 0.6802004067185851 0.5904661429745891 0.6856959946787772\n",
      "0.7010329422849139 0.7238877366693401 0.7243302276967828 0.7286660844541564\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1659.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [15:41:29<5:12:28, 1442.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003513251232582 0.7052824711692016 0.6937847788354012 0.68033312716068 0.5911998228658768 0.6852202309094634\n",
      "0.7011541266606061 0.724320956220357 0.7247589718724992 0.7288612798385427\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1668.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [16:05:36<4:48:44, 1443.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7006645777527585 0.706243234969487 0.6943242988392154 0.6805549951848623 0.5912606903863104 0.6852980110986632\n",
      "0.7016104474512144 0.7251924153464898 0.7256226451486603 0.7295690029743849\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1242.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [16:29:37<4:24:30, 1442.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7000524672028084 0.7061324773646154 0.694181937157536 0.6801887934589547 0.5904084233425786 0.6847931364374724\n",
      "0.7013867422383739 0.72486473730183 0.7252721261094398 0.7291145773369708\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1652.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.700703718478499 0.7065655414523905 0.6950053210980657 0.6802540402915839 0.5902398783324061 0.6848154752243005\n",
      "0.702228886985074 0.7255543384635503 0.7259487347009548 0.7298063582511102\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [16:53:41<4:00:33, 1443.33s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1253.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [17:17:45<3:36:32, 1443.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003309354475662 0.7065831218311411 0.695063847282186 0.6802561474700242 0.5906460690689335 0.6852909141543152\n",
      "0.7021338442934743 0.7253673822587202 0.7257650341967763 0.7296949573457088\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1002.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [17:41:51<3:12:33, 1444.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7005542085598587 0.706571552322047 0.6947465963101005 0.6803019997918055 0.5907528716874457 0.6852673334617536\n",
      "0.7019631040493947 0.7251772349682932 0.7255812264308916 0.7294952639252325\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1672.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.7003343478278825 0.7066403928744992 0.6944640343383902 0.6806083197804916 0.5915021890644898 0.6857402936424087\n",
      "0.7017413009470149 0.7252911933652224 0.7256886764572982 0.7297171063811891\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [18:06:01<2:48:42, 1446.00s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1596.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [18:30:11<2:24:42, 1447.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7000121036109193 0.7065356734916223 0.6944452677922716 0.6802606838141128 0.5917326350687241 0.6851362672466134\n",
      "0.7016241411942711 0.725064746279621 0.7254582910636689 0.7293293938353179\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1241.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [18:54:13<2:00:28, 1445.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6995814293072465 0.7062967522395659 0.6938250495089442 0.680321784474931 0.5918548817070949 0.684706679967333\n",
      "0.7010998961748113 0.7246961830080859 0.7251161003863 0.7289954920114209\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1645.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [19:18:19<1:36:22, 1445.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6997747595609668 0.7062842807458544 0.6940357517470892 0.6804239052783755 0.5924903153078046 0.6853857714919609\n",
      "0.7013106384844859 0.7248283896650674 0.7252477496761124 0.7292165810131493\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1253.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [19:42:20<1:12:12, 1444.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6994974639780889 0.7062350367703837 0.6937937343720272 0.6801899649172788 0.5927000113116924 0.6850565032432361\n",
      "0.7010223796107161 0.7245974336550569 0.7250031471835777 0.7288476674671562\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1243.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [20:06:22<48:07, 1443.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6996104086152641 0.706391154402886 0.6935941314150075 0.6802111931121267 0.592554703611374 0.6850283154277997\n",
      "0.7009241302097848 0.7246918718623959 0.7250849355761511 0.7288781935821801\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1203.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6997791415393054 0.7063060921386155 0.6937228110309619 0.6805825452649497 0.5928908163601969 0.685058538591495\n",
      "0.7010188645740936 0.7247369564325775 0.7251392341538762 0.7289241735918243\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [20:30:18<24:01, 1441.34s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 175.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6996984532339019 0.7066057000779193 0.693573964622543 0.6803487636401587 0.5931316325436229 0.6850806120985163\n",
      "0.7008343782189576 0.7247500706383495 0.7251422790377039 0.7289216051308312\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [20:54:25<00:00, 1505.30s/it]\n"
     ]
    }
   ],
   "source": [
    "##RKD  ENSEMBLE\n",
    "for ns in [50]:\n",
    "    n_shots = ns\n",
    "    aucs = []\n",
    "    only_finetune = []\n",
    "    rkd = []\n",
    "    center = False\n",
    "    l2 = True\n",
    "    result = defaultdict(list)\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        backbone = deepcopy(model_finetune)\n",
    "        backbone = backbone.to(device)\n",
    "\n",
    "        modelrcna = deepcopy(model_rcna)\n",
    "        modelrcna = modelrcna.to(device)\n",
    "        \n",
    "        modelrcna_finetune = deepcopy(model_rcna)\n",
    "        modelrcna_finetune = modelrcna_finetune.to(device)\n",
    "        optimizer_nca_finetune = optim.Adam(modelrcna_finetune.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "        exp_lr_scheduler_nca_finetune = lr_scheduler.StepLR(optimizer_nca_finetune, step_size=7, gamma=0.1)\n",
    "        \n",
    "        model_finetune2 = deepcopy(model_finetune)\n",
    "        optimizer_finetune = optim.Adam(model_finetune2.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "        exp_lr_scheduler_finetune = lr_scheduler.StepLR(optimizer_finetune, step_size=7, gamma=0.1)\n",
    "\n",
    "        model_finetune2 = model_finetune2.to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "        class_df, support_df, query_df = get_support_query_dfs(\n",
    "        novel_datasets, [14,15,16,17,18], n_shots=n_shots)\n",
    "        novel_dataset = get_episode_dataset(class_df, support_df, query_df, dt=dt, sc = [14,15,16,17,18])\n",
    "        novel_dataloaders, novel_image_datasets = get_episode_dataloaders_no_transform(\n",
    "        novel_dataset, bs = cfg.batch_size, cfg = cfg)\n",
    "\n",
    "        model_finetune2 = train_fewshot_model_new(model_finetune2, criterion, optimizer_finetune, exp_lr_scheduler_finetune,\n",
    "                           num_epochs=25, pth='resnet18_finetuned.pth', dataloaders=novel_dataloaders, verbose=False,\n",
    "                        network='residual_network', gradient_clipping=gc,\n",
    "                                                  cfg = cfg\n",
    "                                       )\n",
    "        \n",
    "        modelrcna_finetune = train_fewshot_model_new(modelrcna_finetune, novelNCA, optimizer_nca_finetune,\n",
    "                                                     exp_lr_scheduler_nca_finetune,\n",
    "                           num_epochs=25, pth='resnet18_finetuned.pth', dataloaders=novel_dataloaders, verbose=False,\n",
    "                        network='residual_network', gradient_clipping=gc,\n",
    "                                                  cfg = cfg\n",
    "                                       )\n",
    "        \n",
    "        ft_clf_auc = np.mean(evaluate(novel_dataloaders['test'], model_finetune2))\n",
    "        torch.cuda.empty_cache()\n",
    "        result['ft_clf_auc'].append(ft_clf_auc)\n",
    "        \n",
    "        for param in backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        backbone.eval()\n",
    "        model_finetune2.eval()\n",
    "        modelrcna.eval()\n",
    "        modelrcna_finetune.eval()\n",
    "        with torch.no_grad():\n",
    "            prototypes = []\n",
    "            prototypes2 = []\n",
    "            prototypes_simpleshot = []\n",
    "            prototypes_rcna = []\n",
    "            prototypes_rcna_finetune = []\n",
    "            \n",
    "            for idx in range(5):\n",
    "                support_samples = []\n",
    "                support_samples_simpleshot = []\n",
    "                support_samples_rcna = []\n",
    "                support_samples_rcna_finetune = []\n",
    "\n",
    "                for ix in range(len(novel_image_datasets['train'])):\n",
    "                    if novel_image_datasets['train'][ix][1][idx] == 1:\n",
    "                        img_train = novel_image_datasets['train'][ix][0].unsqueeze(0).to(device)\n",
    "                        out, _ = model_finetune2(img_train)\n",
    "                        out_backbone, _ = backbone(img_train)\n",
    "                        out_rcna, _ = modelrcna(img_train)\n",
    "                        out_rcna_finetune, _ = modelrcna_finetune(img_train)\n",
    "                        \n",
    "                        if center:\n",
    "                            out = (out - train_mean_norm)\n",
    "                        if l2:\n",
    "                            out = out / torch.norm(out.float(), p=2, dim=-1, keepdim=True)\n",
    "                            out_backbone = out_backbone  / torch.norm(out_backbone.float(), p=2, dim=-1, keepdim=True)\n",
    "                            out_rcna = out_rcna / torch.norm(out_rcna.float(), p=2, dim=-1, keepdim=True)\n",
    "                            out_rcna_finetune = out_rcna_finetune/torch.norm(out_rcna_finetune.float(), p=2, dim=-1, keepdim=True)\n",
    "                            \n",
    "                        support_samples.append(out)\n",
    "                        support_samples_simpleshot.append(out_backbone)\n",
    "                        support_samples_rcna.append(out_rcna)\n",
    "                        support_samples_rcna_finetune.append(out_rcna_finetune)\n",
    "    \n",
    "                mean_samples = torch.stack(support_samples).mean(dim=0)\n",
    "                mean_samples_simpleshot=  torch.stack(support_samples_simpleshot).mean(dim=0)\n",
    "                mean_samples_rcna = torch.stack(support_samples_rcna).mean(dim=0)\n",
    "                mean_samples_rcna_finetune = torch.stack(support_samples_rcna_finetune).mean(dim=0)\n",
    "                \n",
    "                prototypes.append(mean_samples)\n",
    "                prototypes_simpleshot.append(mean_samples_simpleshot)\n",
    "                prototypes_rcna.append(mean_samples_rcna)\n",
    "                prototypes_rcna_finetune.append(mean_samples_rcna_finetune)\n",
    "                \n",
    "            prototypes = torch.stack(prototypes)\n",
    "            prototypes_simpleshot = torch.stack(prototypes_simpleshot)\n",
    "            prototypes_rcna = torch.stack(prototypes_rcna)\n",
    "            prototypes_rcna_finetune = torch.stack(prototypes_rcna_finetune)\n",
    "\n",
    "            query_samples = []\n",
    "            query_samples2 = []\n",
    "            query_samples_simpleshot = []\n",
    "            query_samples_rcna = []\n",
    "            query_samples_rcna_finetune = []\n",
    "            labels_true = []\n",
    "            for key in range(len(novel_image_datasets['test'])):\n",
    "                img = novel_image_datasets['test'][key][0].unsqueeze(0).to(device)\n",
    "                out_backbone, _ = backbone(img)\n",
    "                query_samples2.append(out_backbone)\n",
    "                out, _ = model_finetune2(img)\n",
    "                out_rcna,_ = modelrcna(img)\n",
    "                out_rcna_finetune,_ = modelrcna_finetune(img)\n",
    "        \n",
    "                if center:\n",
    "                    out = (out - train_mean_norm)\n",
    "                if l2:\n",
    "                    out = out / torch.norm(out.float(), p=2, dim=-1, keepdim=True)\n",
    "                    out_backbone = out_backbone / torch.norm(out_backbone.float(), p=2, dim=-1, keepdim=True)\n",
    "                    out_rcna = out_rcna / torch.norm(out_rcna.float(), p=2, dim=-1, keepdim=True)\n",
    "                    out_rcna_finetune = out_rcna_finetune / torch.norm(out_rcna_finetune.float(), p=2, dim=-1, keepdim=True)\n",
    "                    \n",
    "                query_samples.append(out)\n",
    "                query_samples_simpleshot.append(out_backbone)\n",
    "                query_samples_rcna.append(out_rcna)\n",
    "                query_samples_rcna_finetune.append(out_rcna_finetune)\n",
    "                labels_true.append(novel_image_datasets['test'][key][1][-5:])\n",
    "\n",
    "            query_features = torch.cat([q.unsqueeze(0) for q in query_samples])\n",
    "            query_features2 = torch.cat([q.unsqueeze(0) for q in query_samples2])\n",
    "            query_features_rcna = torch.cat([q.unsqueeze(0) for q in query_samples_rcna])\n",
    "            query_features_DC = torch.pow(query_features2, beta)\n",
    "            query_features_simpleshot =  torch.cat([q.unsqueeze(0) for q in query_samples_simpleshot])\n",
    "            query_features_rcna_finetune = torch.cat([q.unsqueeze(0) for q in query_samples_rcna_finetune])\n",
    "    #         if l2:\n",
    "    #             query_features2 = query_features2 / torch.norm(query_features2.float(), p=2, dim=-1, keepdim=True)\n",
    "        support_data = []\n",
    "        support_label = []\n",
    "        for inputs, labels, uid in novel_dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            features, _ = backbone(inputs.to(device))\n",
    "            support_data.append((features).detach().cpu().numpy())\n",
    "            support_label.append(labels.detach().cpu().numpy())\n",
    "        support_data = np.vstack(support_data)\n",
    "        support_data = np.power(support_data[:, ] ,beta)\n",
    "        support_label = np.vstack(support_label)\n",
    "\n",
    "        # ---- distribution calibration and feature sampling\n",
    "        sampled_data = []\n",
    "        sampled_label = []\n",
    "        num_sampled = int(750/n_shots)\n",
    "        n_ways = 5\n",
    "        for i in range(n_shots*5):\n",
    "            mean, cov = distribution_calibration(support_data[i], base_means, base_cov, k=2)\n",
    "            sampled_data.append(np.random.multivariate_normal(mean=mean, cov=cov, size=num_sampled))\n",
    "            sampled_label.extend([support_label[i]]*num_sampled)\n",
    "\n",
    "        n_ways = 5\n",
    "        sampled_data = np.concatenate([sampled_data[:]]).reshape(n_ways * n_shots * num_sampled, -1)\n",
    "        X_aug = np.concatenate([support_data, sampled_data])\n",
    "        Y_aug = np.concatenate([support_label, sampled_label])\n",
    "\n",
    "        prototypes2, lr_model = train_LR(X_aug, Y_aug, learning_rate=0.001, ep=500, l2 = False)\n",
    "        prototypes2 = 0.5*prototypes2\n",
    "        if center:\n",
    "            prototypes2 = prototypes2 - train_mean_norm4\n",
    "        prototypes2 = torch.from_numpy(prototypes2).to(device)\n",
    "    #     if l2:\n",
    "    #         prototypes2 = prototypes2 / torch.norm(prototypes2.float(), p=2, dim=-1, keepdim=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = euclidean_metric(query_features.squeeze(1), prototypes.squeeze(1))\n",
    "            logits_DC = euclidean_metric(query_features_DC.squeeze(1), prototypes2.squeeze(1))\n",
    "            logits_DC_raw = lr_model(query_features_DC)\n",
    "            \n",
    "            logits_simpleshot =  euclidean_metric(query_features_simpleshot.squeeze(1), prototypes_simpleshot.squeeze(1))\n",
    "            \n",
    "            logits_rcna = euclidean_metric(query_features_rcna.squeeze(1), prototypes_rcna.squeeze(1))  \n",
    "            logits_rcna_finetune = euclidean_metric(query_features_rcna_finetune.squeeze(1), prototypes_rcna_finetune.squeeze(1))  \n",
    "            \n",
    "            logits_comb = logits + logits_DC + logits_simpleshot + logits_rcna\n",
    "            logits_comb_rcna_finetune = logits + logits_DC + logits_simpleshot + logits_rcna + logits_rcna_finetune\n",
    "            \n",
    "            logits_comb_wo_ft = logits_rcna + logits_DC + logits_simpleshot\n",
    "            logits_comb_wo_rcna = logits +  logits_DC + logits_simpleshot\n",
    "            logits_comb_wo_ft = F.softmax(logits_comb_wo_ft, dim=-1)\n",
    "            logits_comb_wo_rcna = F.softmax(logits_comb_wo_rcna, dim=-1)\n",
    "            logits_comb = F.softmax(logits_comb, dim=-1)\n",
    "            logits_comb_rcna_finetune =  F.softmax(logits_comb_rcna_finetune, dim=-1)\n",
    "\n",
    "            logits_ft = F.softmax(logits, dim=-1)\n",
    "            logits_simpleshot = F.softmax(logits_simpleshot, dim=-1)\n",
    "            logits_DC = F.softmax(logits_DC, dim=-1)\n",
    "            logits_rcna = F.softmax(logits_rcna, dim=-1)\n",
    "            logits_rcna_finetune = F.softmax(logits_rcna_finetune, dim=-1)\n",
    "            \n",
    "            all_preds = logits_comb.cpu().numpy()\n",
    "\n",
    "            y_trues = torch.cat([l.unsqueeze(0) for l in labels_true])[:,-5:].cpu().numpy()\n",
    "\n",
    "            y_trues = np.array(y_trues)\n",
    "            \n",
    "            result['DC'].append(np.mean(evaluate_fewshot(logits_DC.cpu().numpy(), y_trues)))\n",
    "            result['FT'].append(np.mean(evaluate_fewshot(logits_ft.cpu().numpy(), y_trues)))\n",
    "            result['simpleshot'].append(np.mean(evaluate_fewshot(logits_simpleshot.cpu().numpy(), y_trues)))\n",
    "    \n",
    "            result['ccvd'].append(np.mean(evaluate_fewshot(all_preds, y_trues)))\n",
    "            result['ccvd_wo_rcna'].append(np.mean(evaluate_fewshot(logits_comb_wo_rcna.cpu().numpy(), y_trues)))\n",
    "            result['ccvd_wo_ft'].append(np.mean(evaluate_fewshot(logits_comb_wo_ft.cpu().numpy(), y_trues)))\n",
    "            result['ccvd_rcna_finetune'].append(np.mean(evaluate_fewshot(logits_comb_rcna_finetune.cpu().numpy(), y_trues)))\n",
    "            \n",
    "            result['rcna'].append(np.mean(evaluate_fewshot(logits_rcna.cpu().numpy(), y_trues)))\n",
    "            result['dc_raw'].append(np.mean(evaluate_fewshot(logits_DC_raw.squeeze(1).cpu().numpy(), y_trues)))\n",
    "            result['rcna_finetune'].append(np.mean(evaluate_fewshot(logits_rcna_finetune.cpu().numpy(), y_trues)))\n",
    "\n",
    "        print(np.mean(result['simpleshot']), np.mean(result['FT']), np.mean(result['DC']), np.mean(result['rcna']), \n",
    "              np.mean(result['dc_raw']), np.mean(result['rcna_finetune']))\n",
    "        print(np.mean(result['ccvd_wo_ft']), np.mean(result['ccvd_wo_rcna']),  np.mean(result['ccvd']),\n",
    "              np.mean(result['ccvd_rcna_finetune']))\n",
    "        print('---------')\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    filename = \"results_june17_5_\" + str(n_shots) + \".csv\"\n",
    "    pd.DataFrame(result).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d22474ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simpl = [ v for i,v in enumerate(result['simpleshot']) if i %2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c59f5933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6716824727656878, 0.6716824727656878)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result['simpleshot']), np.mean(simpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c9ff785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result['simpleshot'] = simpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d558292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['ft_clf_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec2607e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"results_june17_4_\" + str(n_shots) + \".csv\"\n",
    "pd.DataFrame(result).to_csv(filename)\n",
    "n_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3731dc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48, 0.77, 0.33999999999999997, 0.736111111111111, 0.5900000000000001]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_fewshot(logits_DC_raw.squeeze(1).cpu().numpy(), y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8ed6d88",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 503.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [04:29<3:40:02, 269.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5596893704850361 0.5324220846233231 0.5566718266253871 0.6065624355005159 0.4991805985552116 0.5868771929824562\n",
      "0.5609938080495356 0.5387543859649123 0.5480175438596492 0.5501733746130031\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1254.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [08:56<3:34:32, 268.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6709148606811146 0.6610356037151703 0.650265737874097 0.6999654282765738 0.5800288957688339 0.6504736842105263\n",
      "0.6631811145510836 0.662078947368421 0.6648333333333334 0.666156862745098\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1662.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [13:10<3:25:02, 261.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6650306976591807 0.6717000507805461 0.6586539715301325 0.6753619506282046 0.5785029239766082 0.6151757334512752\n",
      "0.665264533883729 0.6717460645076744 0.6725241207594149 0.672073140367258\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1253.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [17:56<3:27:58, 271.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6514236080397071 0.6489921433485675 0.6379290751388275 0.6673050887021476 0.582360380116959 0.6340126480416728\n",
      "0.6455485466116271 0.6554199284977149 0.6568506929087425 0.6622368728193031\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1652.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6563202221239373 0.6571260455059217 0.653391075728537 0.6651013809032384 0.5759595606663718 0.6321086392451718\n",
      "0.6598942896456828 0.6686000343997248 0.6711147378249546 0.674484569266303\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [22:15<3:19:56, 266.60s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1253.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6610116058119154 0.6386430905695611 0.6538527691778466 0.6677835520172981 0.5626398963094009 0.6302719093485347\n",
      "0.6607453642275624 0.6607563475682671 0.6634842334594656 0.6675011261814667\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [26:58<3:19:37, 272.21s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1253.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [31:11<3:10:46, 266.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6659643576728937 0.6419468524251805 0.6599504222741729 0.6633234837794767 0.5788974502081533 0.642499922776128\n",
      "0.6657270803058065 0.6656551006367459 0.6684468032827166 0.6733809629114803\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1242.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [35:23<3:02:58, 261.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6574011437908497 0.6291638133323505 0.6572118408767016 0.6516515737874098 0.5800081177207725 0.6385406070322865\n",
      "0.6603652052926434 0.6583187226645044 0.6607307607253428 0.665580105287729\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1648.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [39:30<2:55:34, 256.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6473299315827696 0.6126463080358849 0.6524710468982915 0.6437229620893192 0.5753609705090613 0.6245403186615777\n",
      "0.6548765623208348 0.6516006765279211 0.6535497785858984 0.6576566497944206\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1653.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [43:39<2:49:47, 254.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6396061919504644 0.6072176421445772 0.6393541967664259 0.6343780996609171 0.5696898373384441 0.6200476903041918\n",
      "0.6433605607155143 0.6434684210526316 0.6447535898569955 0.6490710501744557\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1650.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [47:53<2:45:26, 254.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363112415620157 0.6093124611886221 0.6336582923440509 0.6299200161723383 0.568131643726071 0.6220156719785203\n",
      "0.6384397290016485 0.6405810738968634 0.6416815501320146 0.6451094760073087\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1671.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [52:03<2:40:08, 252.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6269663660785952 0.6043336527593494 0.630792899323472 0.6201802607007716 0.5705106516290727 0.6139073009320687\n",
      "0.6336961132406179 0.6360505471194325 0.6360399425852212 0.6394811497698494\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1650.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [56:08<2:34:33, 250.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6232925186268841 0.5983470592015483 0.6265536408895542 0.6066499109765364 0.5707277809909389 0.6084638821790525\n",
      "0.6288037382294349 0.6314703463031636 0.6310893731311688 0.6330985949035484\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1676.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [1:00:14<2:29:33, 249.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6331887386533561 0.6087907022458106 0.6349431439242365 0.6155730555380047 0.580265365795441 0.6198988226869695\n",
      "0.6371100949151591 0.6408211038801486 0.6410092931909607 0.6444686260469099\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1669.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [1:04:26<2:25:50, 250.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6352030566612611 0.6164175209264992 0.6392381623994629 0.6179266647009681 0.5831693121693122 0.6245675561452652\n",
      "0.6405612347863123 0.6462587612822907 0.6464180303700429 0.6499976182285779\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1272.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [1:08:34<2:21:19, 249.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6255977904319623 0.6105740699788688 0.6315735800899307 0.6079514027102069 0.5787904657477025 0.6160742726915328\n",
      "0.6327141275369798 0.6389476847756647 0.6384917363875375 0.641749960071748\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1678.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [1:12:39<2:16:31, 248.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6275696623334577 0.6088647888463952 0.6320320770206947 0.6091604429181373 0.5803784692411535 0.6160921363385397\n",
      "0.6343705905478807 0.6389183541321586 0.6387191840616536 0.6424512665747413\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1658.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [1:16:46<2:12:09, 247.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6237117849088953 0.6073080468054669 0.6272713687814306 0.6096397789135147 0.5799324591435014 0.6166391277758668\n",
      "0.629517930174019 0.6339083847964138 0.6334321247017326 0.6374358035611905\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1402.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [1:20:56<2:08:24, 248.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6268122990655173 0.6094942257604797 0.6327225481143518 0.6109445841125001 0.5796798471928014 0.6126291451021777\n",
      "0.6345697279835295 0.6382107927196733 0.6374825906355156 0.6409633655863083\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1669.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [1:25:05<2:04:17, 248.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6271117339918424 0.6097781144036563 0.6341388716890264 0.6128914037544843 0.5835057619539044 0.6191511364194802\n",
      "0.636759163840975 0.6393999004865104 0.6388081085065606 0.6435148017101577\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1649.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [1:29:10<1:59:35, 247.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6281301982781416 0.610750349262512 0.6363211132406178 0.6121919212129296 0.5848772257440987 0.6234661665835926\n",
      "0.639131190487891 0.6420816782853492 0.6415432769599069 0.6467391447807193\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 2467.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [1:33:14<1:55:02, 246.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6306649500310492 0.6136049035244082 0.6384388935797604 0.614628021703099 0.5863670852711099 0.6266679209163729\n",
      "0.640991673702974 0.6442556826558374 0.6438063094456283 0.649232850396937\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 2462.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [1:37:24<1:51:19, 247.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6280758684862199 0.6144866599576521 0.636406047087027 0.6136489849944554 0.5862742106758797 0.6267475241812973\n",
      "0.6391052920023845 0.6427580513517384 0.6423904945654845 0.6473314787394744\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1653.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [1:41:44<1:48:51, 251.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6269705769734796 0.6123146837682442 0.6345782122790636 0.611576726743329 0.5872723925827641 0.6225246480171015\n",
      "0.637088617172015 0.6411099941438564 0.6408864071944568 0.6452947974511442\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1671.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [1:45:51<1:44:11, 250.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6273357137942898 0.6125805926581159 0.6350625357511426 0.6095344596786084 0.5854162671384343 0.6221258007764509\n",
      "0.6376231008894786 0.6413092201090963 0.6408399567546317 0.6455202486608678\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1242.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [1:50:02<1:40:04, 250.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6234110833267181 0.6087053606867848 0.632398074749468 0.602408977761145 0.582719195235449 0.6138521813583733\n",
      "0.6336941647104186 0.6368947179411576 0.636343075826822 0.6399988895693229\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1653.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [1:54:13<1:36:00, 250.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6208825686219909 0.6051756005846133 0.6308772202838251 0.6021120766695243 0.5807088336309182 0.6110016271615858\n",
      "0.6324001297725068 0.6345211612910271 0.633959380113319 0.6376375952590263\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1672.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [1:58:24<1:31:56, 250.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6180413647915308 0.602453097028285 0.6299954069347038 0.6018086980406199 0.5781898189100201 0.6091341922734006\n",
      "0.6312445776556237 0.6324653984400778 0.6318669915334556 0.6355023456751121\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1265.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [2:02:34<1:27:39, 250.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216887426476944 0.6058899090186588 0.6333829062175386 0.60325797675392 0.5810513767515475 0.6091771950159374\n",
      "0.6350153417688915 0.6369298465907839 0.6362973398675865 0.6393097517288827\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1648.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [2:06:46<1:23:37, 250.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6201263108752274 0.6044315486428489 0.6330539494160238 0.5996376676986584 0.5801197282421741 0.6035315085098367\n",
      "0.6345357020000983 0.6362244991563877 0.6356048888561273 0.6382813815584713\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1670.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n",
      "0.6196015798509558 0.598830757317075 0.630708689021732 0.5997931023003429 0.578982872266054 0.6024747479070859\n",
      "0.6329009906169599 0.6332189550409865 0.6327891114566937 0.6357414614968794\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [2:11:01<1:19:52, 252.22s/it]C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1654.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [2:15:11<1:15:28, 251.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6170113780161188 0.5996258070114011 0.6289912104096025 0.5989639371099318 0.5774503822362278 0.6047474538060837\n",
      "0.6309036930561698 0.6322082227627893 0.6319458427011155 0.6353220658877586\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1652.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [2:19:24<1:11:21, 251.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6193607712090685 0.5991126025104354 0.627653358738498 0.6016097477800265 0.5789176335074168 0.6050682886658117\n",
      "0.6298058545055448 0.6309727289108095 0.6305638732898795 0.6343606088900207\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1657.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [2:23:39<1:07:28, 253.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6180865355430099 0.6004101162652884 0.6279090698198784 0.600474191534199 0.5781947378538619 0.6016248088502686\n",
      "0.6291303518311349 0.6315623805765856 0.6309890795327419 0.634325824653907\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1654.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [2:27:51<1:03:07, 252.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.619326256818517 0.6019234465716112 0.6291032644636801 0.6026590804742951 0.5781442085606172 0.6009810984042738\n",
      "0.6305240622564815 0.6325519442864865 0.6320370400791896 0.6352703411189037\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1405.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [2:32:07<59:10, 253.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6223920804189124 0.603993636733446 0.6299745837906312 0.6041677382453957 0.5789626524098918 0.6012596448910946\n",
      "0.6318502294680055 0.6339408522668326 0.6337700917599007 0.6367389525010785\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1655.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [2:36:25<55:15, 255.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6252994542530148 0.6044954682679142 0.6324721886858109 0.6051864385393798 0.5824368718563765 0.6014418166507948\n",
      "0.634608189126765 0.6361482355863161 0.6360835601191638 0.6388441586212484\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1654.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [2:40:38<50:53, 254.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6224499264156265 0.6011488596361907 0.6296674063900721 0.6037240922223 0.5803035045042947 0.6021759733440928\n",
      "0.631688478807959 0.6328033389717844 0.6328177648714148 0.6359993689073044\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1687.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [2:44:54<46:43, 254.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235168873667327 0.6004480866570651 0.6283892561973057 0.6052005025131962 0.5803488037590204 0.6042328004526145\n",
      "0.6305713781689014 0.6319710746196814 0.6319808571201759 0.6349994814840016\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1654.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [2:49:10<42:30, 255.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6234445771290973 0.6013837829868789 0.62825596589513 0.6041964297999902 0.5801827110668829 0.6033529098481498\n",
      "0.6301088898717382 0.6322784706865202 0.6322880086245025 0.6349698369698757\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1650.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [2:53:25<38:16, 255.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624564711635617 0.6027229359865469 0.6292487243934801 0.603528069336421 0.5812050900805337 0.6011379530845287\n",
      "0.6314784857888385 0.6331324077769747 0.6331213776909994 0.6354814637022973\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1252.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [2:57:44<34:09, 256.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6250763042058929 0.6038592934249724 0.6287056015388611 0.6041617933723197 0.5819279085903367 0.5989275084302728\n",
      "0.6307753393755162 0.6325268177446417 0.632468431232142 0.6349074419241381\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1649.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [3:01:57<29:47, 255.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6239201983526989 0.6028381995801176 0.6279481849859486 0.6037947570705149 0.5803761215624561 0.5988602794034791\n",
      "0.6300378414115544 0.6314041139099459 0.6314020230695297 0.6338346121802454\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1653.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [3:06:12<25:31, 255.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6240267435522854 0.6023988564325252 0.6275813212844946 0.6047445876277145 0.5809553685908175 0.5988426262849638\n",
      "0.6293976557927796 0.6311358537832996 0.6311830623796569 0.6335589223727769\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1655.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [3:10:23<21:09, 253.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6246932429111995 0.6013013175640627 0.628287302133329 0.6057047886601035 0.581905548184186 0.6001131150315877\n",
      "0.6300079223112247 0.631379367809502 0.6315350604179295 0.6342173827815727\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1654.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [3:14:38<16:57, 254.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6242044582897995 0.6009270896764503 0.6281179216156333 0.6039118517735088 0.5810794847305818 0.597786334976401\n",
      "0.6301029475863572 0.6316785538013833 0.631874340048758 0.6342860139479133\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1213.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [3:18:50<12:40, 253.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6240500521223793 0.6009521571973321 0.6274696493005563 0.604058557428197 0.5807802944992854 0.5978035723434577\n",
      "0.6294818695675359 0.6311030862512979 0.6314066889167015 0.633649842691836\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1251.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [3:23:01<08:25, 252.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6254349046636198 0.6042388508034793 0.6279263523391813 0.6050123204252461 0.5805231322792275 0.5997428584737988\n",
      "0.6302080026455026 0.6332755679025996 0.6336424640031452 0.6361482699805068\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 1652.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [3:27:10<04:11, 251.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6244111278596651 0.605012725892362 0.6273518916338465 0.6039984635458193 0.5801703764212451 0.5997306135486776\n",
      "0.6294658244250081 0.633232691071416 0.6338201526224525 0.6365760830648048\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negated_target = torch.tensor(~(target.type(torch.bool)),  dtype=torch.int16)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negatives_matrix = torch.tensor(~all_pos.type(torch.bool), dtype=torch.int16).to(device)\n",
      "C:\\Users\\saura\\AppData\\Local\\Temp/ipykernel_2912/1712804310.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(all_pos, dtype=torch.int16)\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 2456.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [3:31:17<00:00, 253.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6247411145510836 0.6056154248366012 0.6266574863629663 0.6050211666420955 0.5801074436090226 0.6009876844070962\n",
      "0.6294062813897489 0.6331899076121676 0.6338267777286353 0.6368370583321047\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##RKD  ENSEMBLE\n",
    "for ns in [5]:\n",
    "    n_shots = ns\n",
    "    aucs = []\n",
    "    only_finetune = []\n",
    "    rkd = []\n",
    "    center = False\n",
    "    l2 = True\n",
    "    result = defaultdict(list)\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        backbone = deepcopy(model_finetune)\n",
    "        backbone = backbone.to(device)\n",
    "\n",
    "        modelrcna = deepcopy(model_rcna)\n",
    "        modelrcna = modelrcna.to(device)\n",
    "        \n",
    "        modelrcna_finetune = deepcopy(model_rcna)\n",
    "        modelrcna_finetune = modelrcna_finetune.to(device)\n",
    "        optimizer_nca_finetune = optim.Adam(modelrcna_finetune.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "        exp_lr_scheduler_nca_finetune = lr_scheduler.StepLR(optimizer_nca_finetune, step_size=7, gamma=0.1)\n",
    "        \n",
    "        model_finetune2 = deepcopy(model_finetune)\n",
    "        optimizer_finetune = optim.Adam(model_finetune2.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "        exp_lr_scheduler_finetune = lr_scheduler.StepLR(optimizer_finetune, step_size=7, gamma=0.1)\n",
    "\n",
    "        model_finetune2 = model_finetune2.to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "        class_df, support_df, query_df = get_support_query_dfs(\n",
    "        novel_datasets, [14,15,16,17,18], n_shots=n_shots)\n",
    "        novel_dataset = get_episode_dataset(class_df, support_df, query_df, dt=dt, sc = [14,15,16,17,18])\n",
    "        novel_dataloaders, novel_image_datasets = get_episode_dataloaders_no_transform(\n",
    "        novel_dataset, bs = cfg.batch_size, cfg = cfg)\n",
    "\n",
    "        model_finetune2 = train_fewshot_model_new(model_finetune2, criterion, optimizer_finetune, exp_lr_scheduler_finetune,\n",
    "                           num_epochs=22, pth='resnet18_finetuned.pth', dataloaders=novel_dataloaders, verbose=False,\n",
    "                        network='residual_network', gradient_clipping=gc,\n",
    "                                                  cfg = cfg\n",
    "                                       )\n",
    "        \n",
    "        modelrcna_finetune = train_fewshot_model_new(modelrcna_finetune, novelNCA, optimizer_nca_finetune,\n",
    "                                                     exp_lr_scheduler_nca_finetune,\n",
    "                           num_epochs=22, pth='resnet18_finetuned.pth', dataloaders=novel_dataloaders, verbose=False,\n",
    "                        network='residual_network', gradient_clipping=gc,\n",
    "                                                  cfg = cfg\n",
    "                                       )\n",
    "        \n",
    "        ft_clf_auc = np.mean(evaluate(novel_dataloaders['test'], model_finetune2))\n",
    "        torch.cuda.empty_cache()\n",
    "        result['ft_clf_auc'].append(ft_clf_auc)\n",
    "        \n",
    "        for param in backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        backbone.eval()\n",
    "        model_finetune2.eval()\n",
    "        modelrcna.eval()\n",
    "        modelrcna_finetune.eval()\n",
    "        with torch.no_grad():\n",
    "            prototypes = []\n",
    "            prototypes2 = []\n",
    "            prototypes_simpleshot = []\n",
    "            prototypes_rcna = []\n",
    "            prototypes_rcna_finetune = []\n",
    "            \n",
    "            for idx in range(5):\n",
    "                support_samples = []\n",
    "                support_samples_simpleshot = []\n",
    "                support_samples_rcna = []\n",
    "                support_samples_rcna_finetune = []\n",
    "\n",
    "                for ix in range(len(novel_image_datasets['train'])):\n",
    "                    if novel_image_datasets['train'][ix][1][idx] == 1:\n",
    "                        img_train = novel_image_datasets['train'][ix][0].unsqueeze(0).to(device)\n",
    "                        out, _ = model_finetune2(img_train)\n",
    "                        out_backbone, _ = backbone(img_train)\n",
    "                        out_rcna, _ = modelrcna(img_train)\n",
    "                        out_rcna_finetune, _ = modelrcna_finetune(img_train)\n",
    "                        \n",
    "                        if center:\n",
    "                            out = (out - train_mean_norm)\n",
    "                        if l2:\n",
    "                            out = out / torch.norm(out.float(), p=2, dim=-1, keepdim=True)\n",
    "                            out_backbone = out_backbone  / torch.norm(out_backbone.float(), p=2, dim=-1, keepdim=True)\n",
    "                            out_rcna = out_rcna / torch.norm(out_rcna.float(), p=2, dim=-1, keepdim=True)\n",
    "                            out_rcna_finetune = out_rcna_finetune/torch.norm(out_rcna_finetune.float(), p=2, dim=-1, keepdim=True)\n",
    "                            \n",
    "                        support_samples.append(out)\n",
    "                        support_samples_simpleshot.append(out_backbone)\n",
    "                        support_samples_rcna.append(out_rcna)\n",
    "                        support_samples_rcna_finetune.append(out_rcna_finetune)\n",
    "    \n",
    "                mean_samples = torch.stack(support_samples).mean(dim=0)\n",
    "                mean_samples_simpleshot=  torch.stack(support_samples_simpleshot).mean(dim=0)\n",
    "                mean_samples_rcna = torch.stack(support_samples_rcna).mean(dim=0)\n",
    "                mean_samples_rcna_finetune = torch.stack(support_samples_rcna_finetune).mean(dim=0)\n",
    "                \n",
    "                prototypes.append(mean_samples)\n",
    "                prototypes_simpleshot.append(mean_samples_simpleshot)\n",
    "                prototypes_rcna.append(mean_samples_rcna)\n",
    "                prototypes_rcna_finetune.append(mean_samples_rcna_finetune)\n",
    "                \n",
    "            prototypes = torch.stack(prototypes)\n",
    "            prototypes_simpleshot = torch.stack(prototypes_simpleshot)\n",
    "            prototypes_rcna = torch.stack(prototypes_rcna)\n",
    "            prototypes_rcna_finetune = torch.stack(prototypes_rcna_finetune)\n",
    "\n",
    "            query_samples = []\n",
    "            query_samples2 = []\n",
    "            query_samples_simpleshot = []\n",
    "            query_samples_rcna = []\n",
    "            query_samples_rcna_finetune = []\n",
    "            labels_true = []\n",
    "            for key in range(len(novel_image_datasets['test'])):\n",
    "                img = novel_image_datasets['test'][key][0].unsqueeze(0).to(device)\n",
    "                out_backbone, _ = backbone(img)\n",
    "                query_samples2.append(out_backbone)\n",
    "                out, _ = model_finetune2(img)\n",
    "                out_rcna,_ = modelrcna(img)\n",
    "                out_rcna_finetune,_ = modelrcna_finetune(img)\n",
    "        \n",
    "                if center:\n",
    "                    out = (out - train_mean_norm)\n",
    "                if l2:\n",
    "                    out = out / torch.norm(out.float(), p=2, dim=-1, keepdim=True)\n",
    "                    out_backbone = out_backbone / torch.norm(out_backbone.float(), p=2, dim=-1, keepdim=True)\n",
    "                    out_rcna = out_rcna / torch.norm(out_rcna.float(), p=2, dim=-1, keepdim=True)\n",
    "                    out_rcna_finetune = out_rcna_finetune / torch.norm(out_rcna_finetune.float(), p=2, dim=-1, keepdim=True)\n",
    "                    \n",
    "                query_samples.append(out)\n",
    "                query_samples_simpleshot.append(out_backbone)\n",
    "                query_samples_rcna.append(out_rcna)\n",
    "                query_samples_rcna_finetune.append(out_rcna_finetune)\n",
    "                labels_true.append(novel_image_datasets['test'][key][1][-5:])\n",
    "\n",
    "            query_features = torch.cat([q.unsqueeze(0) for q in query_samples])\n",
    "            query_features2 = torch.cat([q.unsqueeze(0) for q in query_samples2])\n",
    "            query_features_rcna = torch.cat([q.unsqueeze(0) for q in query_samples_rcna])\n",
    "            query_features_DC = torch.pow(query_features2, beta)\n",
    "            query_features_simpleshot =  torch.cat([q.unsqueeze(0) for q in query_samples_simpleshot])\n",
    "            query_features_rcna_finetune = torch.cat([q.unsqueeze(0) for q in query_samples_rcna_finetune])\n",
    "    #         if l2:\n",
    "    #             query_features2 = query_features2 / torch.norm(query_features2.float(), p=2, dim=-1, keepdim=True)\n",
    "        support_data = []\n",
    "        support_label = []\n",
    "        for inputs, labels, uid in novel_dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            features, _ = backbone(inputs.to(device))\n",
    "            support_data.append((features).detach().cpu().numpy())\n",
    "            support_label.append(labels.detach().cpu().numpy())\n",
    "        support_data = np.vstack(support_data)\n",
    "        support_data = np.power(support_data[:, ] ,beta)\n",
    "        support_label = np.vstack(support_label)\n",
    "\n",
    "        # ---- distribution calibration and feature sampling\n",
    "        sampled_data = []\n",
    "        sampled_label = []\n",
    "        num_sampled = int(750/n_shots)\n",
    "        n_ways = 5\n",
    "        for i in range(n_shots*5):\n",
    "            mean, cov = distribution_calibration(support_data[i], base_means, base_cov, k=2)\n",
    "            sampled_data.append(np.random.multivariate_normal(mean=mean, cov=cov, size=num_sampled))\n",
    "            sampled_label.extend([support_label[i]]*num_sampled)\n",
    "\n",
    "        n_ways = 5\n",
    "        sampled_data = np.concatenate([sampled_data[:]]).reshape(n_ways * n_shots * num_sampled, -1)\n",
    "        X_aug = np.concatenate([support_data, sampled_data])\n",
    "        Y_aug = np.concatenate([support_label, sampled_label])\n",
    "\n",
    "        prototypes2, lr_model = train_LR(X_aug, Y_aug, learning_rate=0.001, ep=400, l2 = False)\n",
    "        prototypes2 = 0.5*prototypes2\n",
    "        if center:\n",
    "            prototypes2 = prototypes2 - train_mean_norm4\n",
    "        prototypes2 = torch.from_numpy(prototypes2).to(device)\n",
    "    #     if l2:\n",
    "    #         prototypes2 = prototypes2 / torch.norm(prototypes2.float(), p=2, dim=-1, keepdim=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = euclidean_metric(query_features.squeeze(1), prototypes.squeeze(1))\n",
    "            logits_DC = euclidean_metric(query_features_DC.squeeze(1), prototypes2.squeeze(1))\n",
    "            logits_DC_raw = lr_model(query_features_DC)\n",
    "            \n",
    "            logits_simpleshot =  euclidean_metric(query_features_simpleshot.squeeze(1), prototypes_simpleshot.squeeze(1))\n",
    "            \n",
    "            logits_rcna = euclidean_metric(query_features_rcna.squeeze(1), prototypes_rcna.squeeze(1))  \n",
    "            logits_rcna_finetune = euclidean_metric(query_features_rcna_finetune.squeeze(1), prototypes_rcna_finetune.squeeze(1))  \n",
    "            \n",
    "            logits_comb = logits + logits_DC + logits_simpleshot + logits_rcna\n",
    "            logits_comb_rcna_finetune = logits + logits_DC + logits_simpleshot + logits_rcna + logits_rcna_finetune\n",
    "            \n",
    "            logits_comb_wo_ft = logits_rcna + logits_DC + logits_simpleshot\n",
    "            logits_comb_wo_rcna = logits +  logits_DC + logits_simpleshot\n",
    "            logits_comb_wo_ft = F.softmax(logits_comb_wo_ft, dim=-1)\n",
    "            logits_comb_wo_rcna = F.softmax(logits_comb_wo_rcna, dim=-1)\n",
    "            logits_comb = F.softmax(logits_comb, dim=-1)\n",
    "            logits_comb_rcna_finetune =  F.softmax(logits_comb_rcna_finetune, dim=-1)\n",
    "\n",
    "            logits_ft = F.softmax(logits, dim=-1)\n",
    "            logits_simpleshot = F.softmax(logits_simpleshot, dim=-1)\n",
    "            logits_DC = F.softmax(logits_DC, dim=-1)\n",
    "            logits_rcna = F.softmax(logits_rcna, dim=-1)\n",
    "            logits_rcna_finetune = F.softmax(logits_rcna_finetune, dim=-1)\n",
    "            \n",
    "            all_preds = logits_comb.cpu().numpy()\n",
    "\n",
    "            y_trues = torch.cat([l.unsqueeze(0) for l in labels_true])[:,-5:].cpu().numpy()\n",
    "\n",
    "            y_trues = np.array(y_trues)\n",
    "            \n",
    "            result['DC'].append(np.mean(evaluate_fewshot(logits_DC.cpu().numpy(), y_trues)))\n",
    "            result['FT'].append(np.mean(evaluate_fewshot(logits_ft.cpu().numpy(), y_trues)))\n",
    "            result['simpleshot'].append(np.mean(evaluate_fewshot(logits_simpleshot.cpu().numpy(), y_trues)))\n",
    "    \n",
    "            result['ccvd'].append(np.mean(evaluate_fewshot(all_preds, y_trues)))\n",
    "            result['ccvd_wo_rcna'].append(np.mean(evaluate_fewshot(logits_comb_wo_rcna.cpu().numpy(), y_trues)))\n",
    "            result['ccvd_wo_ft'].append(np.mean(evaluate_fewshot(logits_comb_wo_ft.cpu().numpy(), y_trues)))\n",
    "            result['ccvd_rcna_finetune'].append(np.mean(evaluate_fewshot(logits_comb_rcna_finetune.cpu().numpy(), y_trues)))\n",
    "            \n",
    "            result['rcna'].append(np.mean(evaluate_fewshot(logits_rcna.cpu().numpy(), y_trues)))\n",
    "            result['dc_raw'].append(np.mean(evaluate_fewshot(logits_DC_raw.squeeze(1).cpu().numpy(), y_trues)))\n",
    "            result['rcna_finetune'].append(np.mean(evaluate_fewshot(logits_rcna_finetune.cpu().numpy(), y_trues)))\n",
    "\n",
    "        print(np.mean(result['simpleshot']), np.mean(result['FT']), np.mean(result['DC']), np.mean(result['rcna']), \n",
    "              np.mean(result['dc_raw']), np.mean(result['rcna_finetune']))\n",
    "        print(np.mean(result['ccvd_wo_ft']), np.mean(result['ccvd_wo_rcna']),  np.mean(result['ccvd']),\n",
    "              np.mean(result['ccvd_rcna_finetune']))\n",
    "        print('---------')\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    filename = \"results_june17_4_\" + str(n_shots) + \".csv\"\n",
    "    pd.DataFrame(result).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c93949c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('5_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb899db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"ccvd_\" + str(n_shots) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5f12c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ccvd_5.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778eb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141ba70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
